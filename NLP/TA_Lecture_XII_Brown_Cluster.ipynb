{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adfb824",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brown Clustering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7271589d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting brown-clustering\n",
      "  Downloading brown_clustering-0.1.4-py3-none-any.whl (8.1 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ajey kumar\\.conda\\envs\\ta\\lib\\site-packages (from brown-clustering) (4.64.0)\n",
      "Collecting numba\n",
      "  Downloading numba-0.56.0-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 4.6 MB/s eta 0:00:00\n",
      "Collecting numpy<1.21\n",
      "  Downloading numpy-1.20.3-cp39-cp39-win_amd64.whl (13.7 MB)\n",
      "     ---------------------------------------- 13.7/13.7 MB 5.3 MB/s eta 0:00:00\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Downloading llvmlite-0.39.0-cp39-cp39-win_amd64.whl (23.2 MB)\n",
      "     ---------------------------------------- 23.2/23.2 MB 4.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\ajey kumar\\.conda\\envs\\ta\\lib\\site-packages (from numba->brown-clustering) (61.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ajey kumar\\.conda\\envs\\ta\\lib\\site-packages (from tqdm->brown-clustering) (0.4.4)\n",
      "Installing collected packages: numpy, llvmlite, numba, brown-clustering\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.4\n",
      "    Uninstalling numpy-1.22.4:\n",
      "      Successfully uninstalled numpy-1.22.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\Ajey Kumar\\\\.conda\\\\envs\\\\TA\\\\Lib\\\\site-packages\\\\~umpy\\\\.libs\\\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install brown-clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc08bd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting brown_clustering\n",
      "  Using cached brown_clustering-0.1.4-py3-none-any.whl (8.1 kB)\n",
      "Requirement already satisfied: numpy<1.21 in c:\\users\\ajey kumar\\.conda\\envs\\ta\\lib\\site-packages (from brown_clustering) (1.20.3)\n",
      "Collecting numba\n",
      "  Using cached numba-0.56.0-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ajey kumar\\.conda\\envs\\ta\\lib\\site-packages (from brown_clustering) (4.64.0)\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Using cached llvmlite-0.39.0-cp39-cp39-win_amd64.whl (23.2 MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ajey kumar\\.conda\\envs\\ta\\lib\\site-packages (from numba->brown_clustering) (61.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ajey kumar\\.conda\\envs\\ta\\lib\\site-packages (from tqdm->brown_clustering) (0.4.4)\n",
      "Installing collected packages: llvmlite, numba, brown_clustering\n",
      "Successfully installed brown_clustering-0.1.4 llvmlite-0.39.0 numba-0.56.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install brown_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95c1f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import brown_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bb77bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brown_clustering import BigramCorpus, BrownClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f62335f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Hello there good man!\",\n",
    "    \"It is quite windy in London\",\n",
    "    \"How is the weather today?\"\n",
    "]\n",
    "\n",
    "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7967338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hello', 'there', 'good', 'man!'],\n",
       " ['It', 'is', 'quite', 'windy', 'in', 'London'],\n",
       " ['How', 'is', 'the', 'weather', 'today?']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb36dd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a corpus\n",
    "corpus = BigramCorpus(tokenized_corpus, alpha=0.5, min_count=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b18c27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<brown_clustering.data.BigramCorpus at 0x2212f952e20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75290d0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'BigramCorpus' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m corpus:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(t)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'BigramCorpus' object is not iterable"
     ]
    }
   ],
   "source": [
    "for t in corpus:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fb5bace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab count: 14\n",
      "Token count: 15\n",
      "unique 2gram count: 18\n",
      "2gram count: 18.0\n",
      "Laplace smoothing: 0.5\n"
     ]
    }
   ],
   "source": [
    "# (optional) print corpus statistics:\n",
    "corpus.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66736b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a clustering\n",
    "clustering = BrownClustering(corpus, m=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ddce8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<brown_clustering.core.BrownClustering at 0x2212fbd1f40>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "190f4b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:07<00:00,  1.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# train the clustering\n",
    "clusters = clustering.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f17ab03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['is'], ['Hello', 'London', 'good', 'man!', 'in', 'there', 'today?', 'weather', 'windy'], ['How', 'It'], ['the', 'quite']]\n"
     ]
    }
   ],
   "source": [
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6e7035f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Hello': '100000000', 'London': '100000001', 'good': '10000001', 'How': '010', 'It': '011', 'man!': '10000010', 'in': '10000011', 'the': '110', 'quite': '111', 'there': '100001', 'today?': '10001', 'weather': '1001', 'windy': '101', 'is': '00'}\n"
     ]
    }
   ],
   "source": [
    "# get codes for the words\n",
    "print(clustering.codes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "514df604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Hello', '100000000'), ('good', '10000001'), ('man!', '10000010'), ('in', '10000011'), ('there', '100001'), ('today?', '10001'), ('weather', '1001'), ('windy', '101'), ('the', '110'), ('quite', '111')]\n"
     ]
    }
   ],
   "source": [
    "print(clustering.get_similar(\"London\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3e54c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', '100000000'),\n",
       " ('London', '100000001'),\n",
       " ('good', '10000001'),\n",
       " ('man!', '10000010'),\n",
       " ('in', '10000011'),\n",
       " ('there', '100001'),\n",
       " ('today?', '10001'),\n",
       " ('weather', '1001'),\n",
       " ('the', '110'),\n",
       " ('quite', '111')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering.get_similar(\"windy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8185cb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', '100000000'),\n",
       " ('London', '100000001'),\n",
       " ('good', '10000001'),\n",
       " ('man!', '10000010'),\n",
       " ('in', '10000011')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering.get_similar(\"windy\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45cd87b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering.get_similar(\"sunny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf5c6dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package brown_clustering:\n",
      "\n",
      "NAME\n",
      "    brown_clustering\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    core\n",
      "    data\n",
      "    defaultvaluedict\n",
      "    helper\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        brown_clustering.core.BrownClustering\n",
      "        brown_clustering.data.BigramCorpus\n",
      "    \n",
      "    class BigramCorpus(builtins.object)\n",
      "     |  BigramCorpus(corpus: Sequence[Sequence[str]], alpha: float = 1, start_symbol: str = '<s>', end_symbol: str = '</s>', min_count: int = 0)\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, corpus: Sequence[Sequence[str]], alpha: float = 1, start_symbol: str = '<s>', end_symbol: str = '</s>', min_count: int = 0)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  bigram_propa(self, cluster1: Sequence[str], cluster2: Sequence[str]) -> float\n",
      "     |  \n",
      "     |  gather_statistics(self, corpus: Sequence[Sequence[str]], start_symbol: str = '<s>', end_symbol: str = '</s>')\n",
      "     |  \n",
      "     |  gather_vocab(self, corpus: Sequence[Sequence[str]], min_count: int)\n",
      "     |  \n",
      "     |  print_stats(self)\n",
      "     |  \n",
      "     |  ranks(self) -> List[Tuple[str, int]]\n",
      "     |  \n",
      "     |  unigram_propa(self, cluster: Sequence[str]) -> float\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class BrownClustering(builtins.object)\n",
      "     |  BrownClustering(corpus: brown_clustering.data.BigramCorpus, m: int)\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, corpus: brown_clustering.data.BigramCorpus, m: int)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  codes(self) -> Dict[str, str]\n",
      "     |  \n",
      "     |  get_similar(self, word: str, cap: int = 10) -> List[Tuple[str, str]]\n",
      "     |  \n",
      "     |  merge_best(self) -> Tuple[int, int]\n",
      "     |  \n",
      "     |  train(self) -> List[List[str]]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "DATA\n",
      "    __all__ = ['BigramCorpus', 'BrownClustering']\n",
      "\n",
      "FILE\n",
      "    c:\\users\\ajey kumar\\.conda\\envs\\ta\\lib\\site-packages\\brown_clustering\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(brown_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3d1adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try with the corpus of Donald Trump Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f35379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try https://www.kaggle.com/code/rtatman/brown-clustering-trial/notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
